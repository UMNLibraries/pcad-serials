{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCAD notebook 6\n",
    "\n",
    "This notebook loads the pickle files produced by `pcad_5_combine_coverage_calculate`, adds print locations to e lines in each dataframe, then writes out all dataframes to a multi-worksheet Excel file. Congratulations, you made it.\n",
    "\n",
    "Required files/inputs:\n",
    "- `multi_loc_100*.pkl` files produced by PCAD notebook 5 (8 files)\n",
    "- `single_loc_100*.pkl` files produced by PCAD notebook 5 (8 files)\n",
    "\n",
    "Outputs:\n",
    "- `pcad_final_{date}.xlsx` with 1 worksheet per dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "today = str(date.today()).replace('-','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlsv = pd.read_pickle('multi_loc_100single-vendor-data.pkl')\n",
    "df_mlmv = pd.read_pickle('multi_loc_100multi-vendor-data.pkl')\n",
    "df_ml_els = pd.read_pickle('multi_loc_100_vendor_Elsevier.pkl')\n",
    "df_ml_sage = pd.read_pickle('multi_loc_100_vendor_SAGE.pkl')\n",
    "df_ml_spr = pd.read_pickle('multi_loc_100_vendor_Springer.pkl')\n",
    "df_ml_tf = pd.read_pickle('multi_loc_100_vendor_Taylor & Francis.pkl')\n",
    "df_ml_w = pd.read_pickle('multi_loc_100_vendor_Wiley.pkl')\n",
    "df_ml_o = pd.read_pickle('multi_loc_100_vendor_other_and_JSTOR.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 43)\n",
      "(6, 43)\n",
      "(80, 43)\n",
      "(2, 43)\n",
      "(4, 43)\n",
      "(2, 43)\n",
      "(6, 43)\n",
      "(26, 43)\n"
     ]
    }
   ],
   "source": [
    "multi_dfs = [df_mlsv, df_mlmv, df_ml_els, df_ml_sage, df_ml_spr, df_ml_tf, df_ml_w, df_ml_o]\n",
    "for frame in multi_dfs:\n",
    "    print(frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholder cell -- use to drop any empty dataframes from multi_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slsv = pd.read_pickle('single_loc_100single-vendor-data.pkl')\n",
    "df_slmv = pd.read_pickle('single_loc_100multi-vendor-data.pkl')\n",
    "df_sl_els = pd.read_pickle('single_loc_100_vendor_Elsevier.pkl')\n",
    "df_sl_sage = pd.read_pickle('single_loc_100_vendor_SAGE.pkl')\n",
    "df_sl_spr = pd.read_pickle('single_loc_100_vendor_Springer.pkl')\n",
    "df_sl_tf = pd.read_pickle('single_loc_100_vendor_Taylor & Francis.pkl')\n",
    "df_sl_w = pd.read_pickle('single_loc_100_vendor_Wiley.pkl')\n",
    "df_sl_o = pd.read_pickle('single_loc_100_vendor_other_and_JSTOR.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(536, 43)\n",
      "(30, 43)\n",
      "(256, 43)\n",
      "(14, 43)\n",
      "(66, 43)\n",
      "(14, 43)\n",
      "(60, 43)\n",
      "(126, 43)\n"
     ]
    }
   ],
   "source": [
    "single_dfs = [df_slsv, df_slmv, df_sl_els, df_sl_sage, df_sl_spr, df_sl_tf, df_sl_w, df_sl_o]\n",
    "for frame in single_dfs:\n",
    "    print(frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholder cell -- use to drop any empty dataframes from single_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_p_locs_to_e_lines(df):\n",
    "    df['new_locs'] = df['locs']\n",
    "    df['new_locs'].fillna('NOLOCS', inplace=True)\n",
    "    df['new_locs'].astype(str)\n",
    "    df['final_group_id'].astype(int)\n",
    "    locs_df = df.filter(['final_group_id', 'new_locs'], axis=1)\n",
    "    locs_df = locs_df[(locs_df['new_locs']) != 'NOLOCS']\n",
    "    df_locs_all_rows = pd.merge(df, locs_df, how='left', on='final_group_id')\n",
    "    df_locs_clean = df_locs_all_rows.drop('new_locs_x', axis=1)\n",
    "    df_locs_clean.rename(columns={'new_locs_y' : 'P_locs'}, inplace=True)\n",
    "    return df_locs_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "for frame in multi_dfs:\n",
    "    clean_df = add_p_locs_to_e_lines(frame)\n",
    "    all_dfs.append(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in single_dfs:\n",
    "    clean_df = add_p_locs_to_e_lines(frame)\n",
    "    all_dfs.append(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'pcad_final_{today}.xlsx') as writer:\n",
    "    i = 0\n",
    "    for df in all_dfs:\n",
    "        sheet = f'Sheet{str(i)}'\n",
    "        df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "        i +=1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: you will still have to rename the worksheets in the Excel file manually. TODO, someday: code this bit.* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
